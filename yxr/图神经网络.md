---
title: 图神经网络
description: 
published: true
date: 2023-12-25T09:06:49.171Z
tags: 
editor: markdown
dateCreated: 2023-12-24T12:31:49.575Z
---

# 图神经网络

## A Comprehensive Survey on Graph Neural Networks

> 尽管传统的深度学习方法被应用在提取欧氏空间数据的特征方面取得了巨大的成功，但许多实际应用场景中的数据是从非欧式空间生成的，传统的深度学习方法在处理非欧式空间数据上的表现却仍难以使人满意。例如，在电子商务中，一个基于图（Graph）的学习系统能够利用用户和产品之间的交互来做出非常准确的推荐，但图的复杂性使得现有的深度学习算法在处理时面临着巨大的挑战。这是因为图是不规则的，每个图都有一个大小可变的无序节点，图中的每个节点都有不同数量的相邻节点，导致一些重要的操作（例如卷积）在图像（Image）上很容易计算，但不再适合直接用于图。此外，现有深度学习算法的一个核心假设是数据样本之间彼此独立。然而，对于图来说，情况并非如此，图中的每个数据样本（节点）都会有边与图中其他实数据样本（节点）相关，这些信息可用于捕获实例之间的相互依赖关系。

图神经网络可以分为四类：

1.循环图神经网络
2.卷积图神经网络
3.图自编码器
4.时空图神经网络


## 2.Hypergraph Learning: Methods and Practices

### 2.1超图构建
#### 2.2.1基于距离构建超图

一般使用**最邻近搜索**或**聚类**构建，在特征空间中连接相似的顶点，或者位置距离比较近的顶点。超边的权重一般计算为：

$$
w(e) = \sum\limits_{u,v \in e} exp( -\frac{d(\mathbf{X}(u),\mathbf{X}(v))^{2}}{\sigma^{2}})
$$

$u,v$表示超边$e$中的一对顶点，$\sigma$是所有顶点距离的中值。

> 基于特征空间的距离构建超图可能导致不准确，因为噪声或离群值。而且连接多少邻居也是一个重要的问题，自适应学习这个值并不trivial。





